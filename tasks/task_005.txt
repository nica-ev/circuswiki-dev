# Task ID: 5
# Title: Implement content hash calculation
# Status: pending
# Dependencies: 4
# Priority: high
# Description: Create functionality to calculate content hashes for change detection using Test-Driven Development (TDD).
# Details:
Implement methods to calculate content_hash (for Markdown body) and yaml_hash (for frontmatter, excluding technical fields). Use SHA-256 via hashlib. For yaml_hash, exclude fields like content_hash, yaml_hash, and lang. Ensure consistent normalization of content before hashing to avoid false change detection. Follow Test-Driven Development principles by writing tests before implementing the actual functionality for each component.

# Test Strategy:
Create test files with various content and verify hash calculation is consistent. Modify content and verify hash changes. Modify excluded YAML fields and verify yaml_hash doesn't change. Following TDD, write all tests first to define expected behavior before implementing the actual hashing logic.

# Subtasks:
## 1. Implement content normalization functions [done]
### Dependencies: None
### Description: Create utility functions to normalize Markdown content and YAML frontmatter before hashing to ensure consistent hash generation.
### Details:
Following TDD, first write tests for two normalization functions: `normalize_markdown_content(content)` and `normalize_yaml_frontmatter(frontmatter)`. Tests should verify that the Markdown normalization handles line endings (convert to \n), whitespace trimming, and any other text normalization needed for consistency. The YAML normalization tests should verify that frontmatter is converted to a canonical form with consistent key ordering and value representation. Only after tests are complete, implement the actual normalization functions to pass the tests.

<info added on 2025-05-04T01:32:23.880Z>
# TDD Approach

## Test Cases for `normalize_markdown_content`:
- Different line endings (CR, LF, CRLF)
- Leading/trailing whitespace
- Multiple consecutive blank lines
- Mixed indentation (spaces vs tabs)
- Unicode characters and normalization forms
- HTML content within markdown

## Test Cases for `normalize_yaml_frontmatter`:
- Different key ordering
- Nested structures
- Various data types (strings, numbers, booleans, lists)
- Quoted vs unquoted strings
- Multi-line strings
- Empty values

## Implementation Notes:
- For markdown normalization, consider using regex patterns like `re.sub(r'\r\n|\r', '\n', content)` for line endings
- For YAML normalization, parse to Python objects then serialize in canonical form:
  ```python
  def normalize_yaml_frontmatter(frontmatter):
      # Parse YAML to Python dict
      data = yaml.safe_load(frontmatter)
      # Sort keys recursively
      normalized_data = _sort_dict_recursively(data)
      # Return serialized in canonical form
      return yaml.dump(normalized_data, sort_keys=True, default_flow_style=False)
  
  def _sort_dict_recursively(d):
      # Helper function to sort nested dictionaries
      if not isinstance(d, dict):
          return d
      return {k: _sort_dict_recursively(v) for k, v in sorted(d.items())}
  ```
- Consider using libraries like `pyyaml` for YAML handling and `unicodedata` for Unicode normalization
</info added on 2025-05-04T01:32:23.880Z>

<info added on 2025-05-04T01:46:18.985Z>
<info added on 2025-05-05T14:20:45.123Z>
# Implementation Plan (Subtask 5.1)

## File Locations:
- Normalization functions: `src/utils/normalization.py` (New file/directory)
- Tests: `tests/utils/test_normalization.py` (New file/directory)

## Dependencies:
- Ensure `PyYAML` is added to project dependencies (e.g., `requirements.txt` or `pyproject.toml`).

## Test Structure (`pytest`):
- `TestNormalizeMarkdownContent`:
    - test_line_endings (CRLF, LF, CR -> LF)
    - test_whitespace (leading/trailing trim)
    - test_multiple_blank_lines
    - test_mixed_indentation (should preserve unless normalization dictates otherwise - TBD)
    - test_unicode_chars
- `TestNormalizeYAMLFrontmatter`:
    - test_key_ordering (canonical sort)
    - test_nested_structures
    - test_data_types (string, int, bool, list)
    - test_string_quoting
    - test_multiline_strings
    - test_empty_values

## TDD Process:
1. Create the empty files (`src/utils/normalization.py`, `tests/utils/test_normalization.py`).
2. Write failing tests in `test_normalization.py` covering the cases above.
3. Implement the normalization functions in `normalization.py` to make the tests pass.
4. Ensure `PyYAML` dependency is handled.
</info added on 2025-05-05T14:20:45.123Z>
</info added on 2025-05-04T01:46:18.985Z>

<info added on 2025-05-04T01:49:04.098Z>
# Implementation Plan (Subtask 5.1) - CORRECTED PATHS

## File Locations:
- Normalization functions: `translation-py/src/utils/normalization.py` (New file/directory within translation-py)
- Tests: `translation-py/tests/utils/test_normalization.py` (New file/directory within translation-py)

## Dependencies:
- Ensure `PyYAML` is added to project dependencies (e.g., `translation-py/requirements.txt` or `pyproject.toml`).

## Test Structure (`pytest`):
- `TestNormalizeMarkdownContent`:
    - test_line_endings (CRLF, LF, CR -> LF)
    - test_whitespace (leading/trailing trim)
    - test_multiple_blank_lines
    - test_mixed_indentation (should preserve unless normalization dictates otherwise - TBD)
    - test_unicode_chars
- `TestNormalizeYAMLFrontmatter`:
    - test_key_ordering (canonical sort)
    - test_nested_structures
    - test_data_types (string, int, bool, list)
    - test_string_quoting
    - test_multiline_strings
    - test_empty_values

## TDD Process:
1. Create the empty files (`translation-py/src/utils/normalization.py`, `translation-py/tests/utils/test_normalization.py`).
2. Write failing tests in `test_normalization.py` covering the cases above.
3. Implement the normalization functions in `normalization.py` to make the tests pass.
4. Ensure `PyYAML` dependency is handled within the `translation-py` subproject.
</info added on 2025-05-04T01:49:04.098Z>

<info added on 2025-05-04T02:00:07.802Z>
# Implementation Complete (Subtask 5.1)

Implemented and tested the following normalization functions in `translation-py/src/utils/normalization.py`:

1.  **`normalize_markdown_content(content: str) -> str`**
    - Normalizes line endings (CRLF/CR -> LF).
    - Trims leading/trailing whitespace from each line.
    - Reduces multiple consecutive blank lines to a single blank line.
    - Normalizes Unicode characters to NFC form.
    - All corresponding tests in `TestNormalizeMarkdownContent` are passing.

2.  **`normalize_yaml_frontmatter(frontmatter: dict) -> dict`**
    - Recursively sorts dictionary keys alphabetically.
    - Preserves list order but sorts dictionaries within lists.
    - Handles various data types and nested structures.
    - All corresponding tests in `TestNormalizeYAMLFrontmatter` are passing.

Dependencies `pytest` and `PyYAML` added to `translation-py/requirements.txt`.
Necessary `__init__.py` files were created in `src` and `tests` directories.
</info added on 2025-05-04T02:00:07.802Z>

## 2. Implement content_hash calculation for Markdown body [done]
### Dependencies: 5.1
### Description: Create a function to calculate SHA-256 hash for normalized Markdown content.
### Details:
Using TDD, first write tests for the `calculate_content_hash(markdown_content)` function that: 1) Takes raw Markdown content as input, 2) Uses the normalization function from subtask 1, 3) Calculates SHA-256 hash using hashlib, 4) Returns the hexadecimal digest of the hash. Tests should verify hash consistency across equivalent content with different formatting and include error handling for invalid inputs. Only after tests are complete, implement the actual function to pass the tests.

<info added on 2025-05-04T02:04:58.223Z>
## Implementation Details

The `calculate_content_hash` function has been implemented with the following specifics:

```python
def calculate_content_hash(markdown_content: str) -> str:
    """
    Calculate SHA-256 hash for normalized Markdown content.
    
    Args:
        markdown_content: Raw Markdown content as string
        
    Returns:
        Hexadecimal digest of the SHA-256 hash
        
    Raises:
        TypeError: If input is not a string
    """
    if not isinstance(markdown_content, str):
        raise TypeError("Input must be a string")
        
    # Normalize the content first
    normalized_content = normalize_markdown_content(markdown_content)
    
    # Create hash object and update with UTF-8 encoded content
    hash_obj = hashlib.sha256()
    hash_obj.update(normalized_content.encode('utf-8'))
    
    # Return hexadecimal representation
    return hash_obj.hexdigest()
```

Key implementation decisions:
- Type checking is performed before processing to fail fast with clear error messages
- The function properly handles empty strings by returning the hash of an empty string
- UTF-8 encoding ensures consistent byte representation across platforms
- The hexdigest output is lowercase and contains 64 characters (32 bytes represented as hex)

The test suite includes edge cases such as:
- Equivalent Markdown with different line endings (CR, LF, CRLF)
- Content with varying whitespace patterns
- Unicode characters in different normalization forms
- Non-string inputs to verify error handling
</info added on 2025-05-04T02:04:58.223Z>

## 3. Implement yaml_hash calculation for frontmatter [in-progress]
### Dependencies: 5.1
### Description: Create a function to calculate SHA-256 hash for normalized YAML frontmatter, excluding technical fields.
### Details:
Using TDD, first write tests for the `calculate_yaml_hash(frontmatter)` function that: 1) Takes a dictionary of frontmatter as input, 2) Creates a copy and removes technical fields ('content_hash', 'yaml_hash', 'lang', etc.), 3) Uses the YAML normalization function from subtask 1, 4) Calculates SHA-256 hash using hashlib, 5) Returns the hexadecimal digest. Tests should verify all technical fields are properly excluded and hash consistency with different field orderings. Only after tests are complete, implement the actual function to pass the tests.

<info added on 2025-05-04T02:09:38.330Z>
Here's additional information for the yaml_hash calculation subtask:

```python
# Example test cases for calculate_yaml_hash function
def test_calculate_yaml_hash_excludes_technical_fields():
    frontmatter = {
        'title': 'Test Document',
        'date': '2023-01-01',
        'content_hash': 'abc123',  # Should be excluded
        'yaml_hash': 'def456',     # Should be excluded
        'lang': 'en'               # Should be excluded
    }
    
    # Hash should only include title and date
    expected_input_to_hash = {
        'title': 'Test Document',
        'date': '2023-01-01'
    }
    
    # Calculate expected hash manually for verification
    expected_hash = hashlib.sha256(normalize_yaml(expected_input_to_hash).encode()).hexdigest()
    assert calculate_yaml_hash(frontmatter) == expected_hash

def test_calculate_yaml_hash_order_independence():
    frontmatter1 = {'title': 'Test', 'author': 'John', 'date': '2023-01-01'}
    frontmatter2 = {'date': '2023-01-01', 'title': 'Test', 'author': 'John'}
    
    assert calculate_yaml_hash(frontmatter1) == calculate_yaml_hash(frontmatter2)
```

Implementation considerations:
- Define a constant `TECHNICAL_FIELDS = {'content_hash', 'yaml_hash', 'lang', 'path', 'url', 'last_updated'}` to maintain a single source of truth for excluded fields
- Use dictionary comprehension for efficient filtering: `{k: v for k, v in frontmatter.items() if k not in TECHNICAL_FIELDS}`
- Consider adding a parameter to allow custom technical fields to be excluded beyond the default set
- Ensure proper error handling for edge cases (None input, non-dictionary input)
- Document the function with clear docstring explaining normalization process and field exclusion
</info added on 2025-05-04T02:09:38.330Z>

<info added on 2025-05-04T02:13:46.398Z>
<info added>
For the implementation of `calculate_yaml_hash` in `src/utils/hashing.py`, here's a solution to the import error and additional implementation details:

```python
import hashlib
from typing import Dict, Any, Optional, Set
from .yaml_utils import normalize_yaml  # This will work once subtask 1 is complete

# Define technical fields that should be excluded from hash calculation
TECHNICAL_FIELDS: Set[str] = {'content_hash', 'yaml_hash', 'lang', 'path', 'url', 'last_updated'}

def calculate_yaml_hash(frontmatter: Dict[str, Any], 
                        additional_exclude_fields: Optional[Set[str]] = None) -> str:
    """
    Calculate SHA-256 hash for normalized YAML frontmatter, excluding technical fields.
    
    Args:
        frontmatter: Dictionary containing frontmatter fields
        additional_exclude_fields: Optional set of additional fields to exclude
        
    Returns:
        Hexadecimal digest of SHA-256 hash
        
    Raises:
        TypeError: If frontmatter is not a dictionary
    """
    if not isinstance(frontmatter, dict):
        raise TypeError("Frontmatter must be a dictionary")
    
    if frontmatter is None:
        return hashlib.sha256(b"").hexdigest()
    
    # Determine fields to exclude
    exclude_fields = TECHNICAL_FIELDS.copy()
    if additional_exclude_fields:
        exclude_fields.update(additional_exclude_fields)
    
    # Create filtered copy of frontmatter
    filtered_frontmatter = {k: v for k, v in frontmatter.items() if k not in exclude_fields}
    
    # Normalize and hash
    normalized_yaml = normalize_yaml(filtered_frontmatter)
    return hashlib.sha256(normalized_yaml.encode('utf-8')).hexdigest()
```

For temporary testing before subtask 1 is complete, you can create a simple placeholder for `normalize_yaml` in a file called `yaml_utils.py` in the same directory:

```python
def normalize_yaml(data):
    """Placeholder for the real normalize_yaml function from subtask 1"""
    import yaml
    return yaml.dump(data, sort_keys=True)
```

This will allow you to run the tests and verify the functionality of `calculate_yaml_hash` while waiting for the proper implementation of `normalize_yaml`.
</info added>
</info added on 2025-05-04T02:13:46.398Z>

## 4. Integrate hash calculation into document processing workflow [pending]
### Dependencies: 5.2, 5.3
### Description: Update the document processing workflow to calculate and store content and YAML hashes during document operations.
### Details:
Following TDD principles, first write integration tests that verify: 1) Hashes are calculated whenever a document is created or updated, 2) Hashes are stored in the document's metadata, 3) Change detection function correctly compares newly calculated hashes with stored hashes, 4) The system correctly identifies changes and ignores non-semantic differences. Only after tests are complete, modify the document processing code to implement these features and add documentation explaining the hash calculation process and its use in change detection.

## 5. Implement YAML normalization function [pending]
### Dependencies: None
### Description: Create a function `normalize_yaml(data: dict)` in `src/utils/yaml_utils.py` that takes a dictionary, sorts keys recursively, and returns a consistent YAML string representation suitable for hashing.
### Details:
The function should handle nested dictionaries and lists. Use TDD: write tests first in `tests/test_utils.py` covering different data structures, key orders, and nested elements. Ensure consistent output format (e.g., indentation, flow style). Implement the function after tests are written.

