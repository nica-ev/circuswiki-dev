# Task ID: 5
# Title: Implement content hash calculation
# Status: pending
# Dependencies: 4
# Priority: high
# Description: Create functionality to calculate content hashes for change detection using Test-Driven Development (TDD).
# Details:
Implement methods to calculate content_hash (for Markdown body) and yaml_hash (for frontmatter, excluding technical fields). Use SHA-256 via hashlib. For yaml_hash, exclude fields like content_hash, yaml_hash, and lang. Ensure consistent normalization of content before hashing to avoid false change detection. Follow Test-Driven Development principles by writing tests before implementing the actual functionality for each component.

# Test Strategy:
Create test files with various content and verify hash calculation is consistent. Modify content and verify hash changes. Modify excluded YAML fields and verify yaml_hash doesn't change. Following TDD, write all tests first to define expected behavior before implementing the actual hashing logic.

# Subtasks:
## 1. Implement content normalization functions [done]
### Dependencies: None
### Description: Create utility functions to normalize Markdown content and YAML frontmatter before hashing to ensure consistent hash generation.
### Details:
Following TDD, first write tests for two normalization functions: `normalize_markdown_content(content)` and `normalize_yaml_frontmatter(frontmatter)`. Tests should verify that the Markdown normalization handles line endings (convert to \n), whitespace trimming, and any other text normalization needed for consistency. The YAML normalization tests should verify that frontmatter is converted to a canonical form with consistent key ordering and value representation. Only after tests are complete, implement the actual normalization functions to pass the tests.

<info added on 2025-05-04T01:32:23.880Z>
# TDD Approach

## Test Cases for `normalize_markdown_content`:
- Different line endings (CR, LF, CRLF)
- Leading/trailing whitespace
- Multiple consecutive blank lines
- Mixed indentation (spaces vs tabs)
- Unicode characters and normalization forms
- HTML content within markdown

## Test Cases for `normalize_yaml_frontmatter`:
- Different key ordering
- Nested structures
- Various data types (strings, numbers, booleans, lists)
- Quoted vs unquoted strings
- Multi-line strings
- Empty values

## Implementation Notes:
- For markdown normalization, consider using regex patterns like `re.sub(r'\r\n|\r', '\n', content)` for line endings
- For YAML normalization, parse to Python objects then serialize in canonical form:
  ```python
  def normalize_yaml_frontmatter(frontmatter):
      # Parse YAML to Python dict
      data = yaml.safe_load(frontmatter)
      # Sort keys recursively
      normalized_data = _sort_dict_recursively(data)
      # Return serialized in canonical form
      return yaml.dump(normalized_data, sort_keys=True, default_flow_style=False)
  
  def _sort_dict_recursively(d):
      # Helper function to sort nested dictionaries
      if not isinstance(d, dict):
          return d
      return {k: _sort_dict_recursively(v) for k, v in sorted(d.items())}
  ```
- Consider using libraries like `pyyaml` for YAML handling and `unicodedata` for Unicode normalization
</info added on 2025-05-04T01:32:23.880Z>

<info added on 2025-05-04T01:46:18.985Z>
<info added on 2025-05-05T14:20:45.123Z>
# Implementation Plan (Subtask 5.1)

## File Locations:
- Normalization functions: `src/utils/normalization.py` (New file/directory)
- Tests: `tests/utils/test_normalization.py` (New file/directory)

## Dependencies:
- Ensure `PyYAML` is added to project dependencies (e.g., `requirements.txt` or `pyproject.toml`).

## Test Structure (`pytest`):
- `TestNormalizeMarkdownContent`:
    - test_line_endings (CRLF, LF, CR -> LF)
    - test_whitespace (leading/trailing trim)
    - test_multiple_blank_lines
    - test_mixed_indentation (should preserve unless normalization dictates otherwise - TBD)
    - test_unicode_chars
- `TestNormalizeYAMLFrontmatter`:
    - test_key_ordering (canonical sort)
    - test_nested_structures
    - test_data_types (string, int, bool, list)
    - test_string_quoting
    - test_multiline_strings
    - test_empty_values

## TDD Process:
1. Create the empty files (`src/utils/normalization.py`, `tests/utils/test_normalization.py`).
2. Write failing tests in `test_normalization.py` covering the cases above.
3. Implement the normalization functions in `normalization.py` to make the tests pass.
4. Ensure `PyYAML` dependency is handled.
</info added on 2025-05-05T14:20:45.123Z>
</info added on 2025-05-04T01:46:18.985Z>

<info added on 2025-05-04T01:49:04.098Z>
# Implementation Plan (Subtask 5.1) - CORRECTED PATHS

## File Locations:
- Normalization functions: `translation-py/src/utils/normalization.py` (New file/directory within translation-py)
- Tests: `translation-py/tests/utils/test_normalization.py` (New file/directory within translation-py)

## Dependencies:
- Ensure `PyYAML` is added to project dependencies (e.g., `translation-py/requirements.txt` or `pyproject.toml`).

## Test Structure (`pytest`):
- `TestNormalizeMarkdownContent`:
    - test_line_endings (CRLF, LF, CR -> LF)
    - test_whitespace (leading/trailing trim)
    - test_multiple_blank_lines
    - test_mixed_indentation (should preserve unless normalization dictates otherwise - TBD)
    - test_unicode_chars
- `TestNormalizeYAMLFrontmatter`:
    - test_key_ordering (canonical sort)
    - test_nested_structures
    - test_data_types (string, int, bool, list)
    - test_string_quoting
    - test_multiline_strings
    - test_empty_values

## TDD Process:
1. Create the empty files (`translation-py/src/utils/normalization.py`, `translation-py/tests/utils/test_normalization.py`).
2. Write failing tests in `test_normalization.py` covering the cases above.
3. Implement the normalization functions in `normalization.py` to make the tests pass.
4. Ensure `PyYAML` dependency is handled within the `translation-py` subproject.
</info added on 2025-05-04T01:49:04.098Z>

<info added on 2025-05-04T02:00:07.802Z>
# Implementation Complete (Subtask 5.1)

Implemented and tested the following normalization functions in `translation-py/src/utils/normalization.py`:

1.  **`normalize_markdown_content(content: str) -> str`**
    - Normalizes line endings (CRLF/CR -> LF).
    - Trims leading/trailing whitespace from each line.
    - Reduces multiple consecutive blank lines to a single blank line.
    - Normalizes Unicode characters to NFC form.
    - All corresponding tests in `TestNormalizeMarkdownContent` are passing.

2.  **`normalize_yaml_frontmatter(frontmatter: dict) -> dict`**
    - Recursively sorts dictionary keys alphabetically.
    - Preserves list order but sorts dictionaries within lists.
    - Handles various data types and nested structures.
    - All corresponding tests in `TestNormalizeYAMLFrontmatter` are passing.

Dependencies `pytest` and `PyYAML` added to `translation-py/requirements.txt`.
Necessary `__init__.py` files were created in `src` and `tests` directories.
</info added on 2025-05-04T02:00:07.802Z>

## 2. Implement content_hash calculation for Markdown body [done]
### Dependencies: 5.1
### Description: Create a function to calculate SHA-256 hash for normalized Markdown content.
### Details:
Using TDD, first write tests for the `calculate_content_hash(markdown_content)` function that: 1) Takes raw Markdown content as input, 2) Uses the normalization function from subtask 1, 3) Calculates SHA-256 hash using hashlib, 4) Returns the hexadecimal digest of the hash. Tests should verify hash consistency across equivalent content with different formatting and include error handling for invalid inputs. Only after tests are complete, implement the actual function to pass the tests.

<info added on 2025-05-04T02:04:58.223Z>
## Implementation Details

The `calculate_content_hash` function has been implemented with the following specifics:

```python
def calculate_content_hash(markdown_content: str) -> str:
    """
    Calculate SHA-256 hash for normalized Markdown content.
    
    Args:
        markdown_content: Raw Markdown content as string
        
    Returns:
        Hexadecimal digest of the SHA-256 hash
        
    Raises:
        TypeError: If input is not a string
    """
    if not isinstance(markdown_content, str):
        raise TypeError("Input must be a string")
        
    # Normalize the content first
    normalized_content = normalize_markdown_content(markdown_content)
    
    # Create hash object and update with UTF-8 encoded content
    hash_obj = hashlib.sha256()
    hash_obj.update(normalized_content.encode('utf-8'))
    
    # Return hexadecimal representation
    return hash_obj.hexdigest()
```

Key implementation decisions:
- Type checking is performed before processing to fail fast with clear error messages
- The function properly handles empty strings by returning the hash of an empty string
- UTF-8 encoding ensures consistent byte representation across platforms
- The hexdigest output is lowercase and contains 64 characters (32 bytes represented as hex)

The test suite includes edge cases such as:
- Equivalent Markdown with different line endings (CR, LF, CRLF)
- Content with varying whitespace patterns
- Unicode characters in different normalization forms
- Non-string inputs to verify error handling
</info added on 2025-05-04T02:04:58.223Z>

## 3. Implement yaml_hash calculation for frontmatter [pending]
### Dependencies: 5.1
### Description: Create a function to calculate SHA-256 hash for normalized YAML frontmatter, excluding technical fields.
### Details:
Using TDD, first write tests for the `calculate_yaml_hash(frontmatter)` function that: 1) Takes a dictionary of frontmatter as input, 2) Creates a copy and removes technical fields ('content_hash', 'yaml_hash', 'lang', etc.), 3) Uses the YAML normalization function from subtask 1, 4) Calculates SHA-256 hash using hashlib, 5) Returns the hexadecimal digest. Tests should verify all technical fields are properly excluded and hash consistency with different field orderings. Only after tests are complete, implement the actual function to pass the tests.

## 4. Integrate hash calculation into document processing workflow [pending]
### Dependencies: 5.2, 5.3
### Description: Update the document processing workflow to calculate and store content and YAML hashes during document operations.
### Details:
Following TDD principles, first write integration tests that verify: 1) Hashes are calculated whenever a document is created or updated, 2) Hashes are stored in the document's metadata, 3) Change detection function correctly compares newly calculated hashes with stored hashes, 4) The system correctly identifies changes and ignores non-semantic differences. Only after tests are complete, modify the document processing code to implement these features and add documentation explaining the hash calculation process and its use in change detection.

